<h2>Metodo do Gradiente Conjugado</h2>

<p align = "justify">
O Método do Gradiente Conjugado é uma variação do Método do Gradiente que se destaca por sua eficácia na otimização de funções quadráticas e na resolução de sistemas lineares. Enquanto o Método do Gradiente é um algoritmo de otimização geral, o Gradiente Conjugado foi projetado especificamente para lidar com funções quadráticas, embora também possa ser estendido para funções não-quadráticas. Sua notável eficiência torna-o uma escolha popular em uma variedade de aplicações, desde otimização numérica até problemas de física computacional e aprendizado de máquina.
<br><br>
O método do gradiente conjugado realiza iterações para atualizar o ponto \(x\) e a direção \(d\) até que um critério de parada seja atingido. A cada iteração, ele faz o seguinte:
</p>

<table style = "width:100%">
    <tr>\[x_{\text{novo}} = x_{\text{antigo}} + \alpha \cdot d]
    </tr>
</table>

<p align = "justify">
A direção \(d\) é atualizada a cada iteração e é uma parte fundamental do algoritmo. Ela é escolhida de forma a garantir que as direções de pesquisa sejam conjugadas entre si. Em cada iteração subsequente, \(d\) é recalculada para direcionar a pesquisa na direção mais apropriada, com base nas informações coletadas nas iterações anteriores. Aqui está a fórmula geral:
</p>

<table style = "width:100%">
    <tr>\[d_{\text{new}} = -\nabla f_{\text{new}} + \beta d_{\text{old}}\]
    </tr>
</table>

<p align = "justify">
Nesta fórmula, \(d_{\text{new}}\) representa a direção de pesquisa na nova iteração, \(-\nabla f_{\text{new}}\) é o gradiente negativo da função objetivo na nova iteração, apontando na direção de maior crescimento da função, \(d_{\text{old}}\) é a direção de pesquisa na iteração anterior e \(\beta\) é o parâmetro beta, que governa a atualização da direção de pesquisa. O valor de \(\beta\) depende da variação específica do Método do Gradiente Conjugado sendo utilizada (ver equação ...).
</p>

| Método                        | Fórmula do Cálculo de \(\beta\)                                   |
|-------------------------------|-----------------------------------------------------------------|
| Fletcher-Reeves               | \(\beta_{\text{FR}} = \frac{\nabla f(x_{\text{novo}}) \cdot \nabla f(x_{\text{novo}})}{\nabla f(x_{\text{atual}}) \cdot \nabla f(x_{\text{atual}})}\) |
| Polak-Ribiére-Polyak          | \(\beta_{\text{PRP}} = \frac{\nabla f(x_{\text{novo}}) \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}{\nabla f(x_{\text{atual}}) \cdot \nabla f(x_{\text{atual}})}\) |
| Hestenes–Stiefel              | \(\beta_{\text{HS}} = \frac{\nabla f(x_{\text{novo}}) \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}{d_{\text{atual}} \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}\) |
| Dai-Yuan                      | \(\beta_{\text{DY}} = -\frac{\nabla f(x_{\text{novo}}) \cdot \nabla f(x_{\text{novo}})}{d_{\text{atual}} \cdot \nabla f(x_{\text{atual}})}\) |
| Liu-Storey                    | \(\beta_{\text{LS}} = \min\left(0, \frac{\nabla f(x_{\text{novo}}) \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}{d_{\text{atual}} \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}\right)\) |
| Dai-Liao                      | \(\beta_{\text{DL}} = \frac{\nabla f(x_{\text{novo}}) \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}{d_{\text{atual}} \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}\) |
| Davidon-Fletcher-Powell (DFP) | \(\beta_{\text{DFP}} = \frac{d_{\text{atual}} \cdot \nabla f(x_{\text{atual}})}{d_{\text{atual}} \cdot (\nabla f(x_{\text{novo}}) - \nabla f(x_{\text{atual}}))}\) |