<!--Don't delete ths script-->
<script src = "https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id = "MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
<!--Don't delete ths script-->

<h1>Particle Swarm Optimization</h1>

<h2>Theory</h2>

<p align = "justify">
Particle Swarm Optimization (PSO) was developed by James Kennedy and Russell Elberthart [1] in 1995 from behavioral experiences such as schools and flocks of birds [2]. The process takes place through cooperation (group learning) and competition (individual learning) between members of a group [3]. Thus, an individual‚Äôs decision-making will depend on their past performance as well as that of neighboring particles.
<br><br>
The PSO algorithm does not have crossover and mutation functions, so the operation is given by the evolution of a random swarm of individuals arranged in a d-dimensional space, which at each iteration, are updated according to the best individual Objective Function (OF) value and the group. Thus, the PSO algorithm is structured on two principles for particle movement. The first refers to the influence of the group on each individual and the second creates a type of memory in each individual in the swarm.
<br><br>
Therefore, an \(i\) particle will move in a certain direction according to the equation (2). The movement is given as a function of the current position \(\symbf{x}_i^t\) of the speed defined in the equation (1). \(pB\) indicates the best position found so far for the particle \(i\) and \(gB\) indicates the best position found so far for the swarm. \(k\) is the kth component of the design variable vector \(\symbf{x}\). \(w^t\) indicates the inertia weight. \(t\) is the current iteration of the algorithm.
</p>

<table style = "width:100%">
    <tr>
        <td>\[\symbf{v}_{i,k}^{t+1} = \omega^{t}.\symbf{v}_{i,k}^{t} + c_1.r_1(\symbf{pB}_{k}^{t} - \symbf{x}_{i,k}^{t}) + c_2.r_2(\symbf{gB}_{k}^{t} - \symbf{x}_{i,k}^{t})\]</td>
        <td><p align = "left">\[\symbf{v}_{k} = \in \{ \symbf{v}_{min,k}, \symbf{v}_{max,k} \} \]</p></td>
        <td><p align = "right">(1)</p></td>
    </tr>
</table>

<p align = "justify">
\(\symbf{v}_{max}\) is the upper boundary of the velocity and \(\symbf{v}_{min}\) is the lower boundary of the velocity. \(r_1\) and \(r_2\) are random numbers between (0,1), and \(c_1\) and \(c_2\) represent the constants of the cognitive term and social term.
</p>

<table style = "width:100%">
    <tr>
        <td>\[\symbf{x}_{i,k}^{t+1} = \symbf{x}_{i,k}^{t} + \symbf{v}_{i,k}^{t+1}\]</td>
        <td><p align = "right">(2)</p></td>
    </tr>
</table>

<h3><i>Velocity handling</i></h3>

<p align = "justify">
Initialization \(\symbf{v}_{max}\) is important and is typically chosen from 0.1 to 1.0 times the lookup range of the potential solution space (\(\symbf{x}_{upper}-\symbf{x}_{lower}\)). To restrict the movement of the swarm particles within the lookup area, each velocity component at ùëó-th dimension is being restricted to the range \([\symbf{v}_{min}, \symbf{v}_{max}]\). \(\symbf{v}_{min}\) can be adopted \(-\symbf{v}_{max}\). 
</p>

<h3><i>Acceleration coefficients</i></h3>

<p align = "justify">
Impact of different values of \(c_1\) and \(c_2\) is explained below [4].
</p>

<dl>
  <dt>\(c_1 = c_2 = 0\)</dt>
    <dd><p align = "justify">In this case, the particle moves on with the same current speed till it reaches the boundary of the search space as its velocity is independent from the impact of personal best and global best position.</p></dd>
  <dt>\(c_1 > 0\) and \(c_2 = 0\)</dt>
    <dd><p align = "justify">Here, the social component of the velocity does not influence the particle‚Äôs velocity and particle will move in the global search space according to its own best position.</p></dd>
  <dt>\(c_1 = 0\) and \(c_2 > 0\)</dt>
    <dd><p align = "justify">Here, the cognitive component of the velocity does not influence the particle‚Äôs velocity and particle will move in the global search space according to its neighbor‚Äôs best position.</p></dd>
  <dt>\(c_1 = c_2\)</dt>
    <dd><p align = "justify">The particle is attracted towards the average of both pbest and gbest position.</p></dd>
  <dt>\(c_1 >> c_2\)</dt>
    <dd><p align = "justify">Here, the personal best position will generally effect the particle‚Äôs velocity more, that leads to excessive wandering in the search space.</p></dd>
  <dt>\(c_1 << c_2\)</dt>
    <dd><p align = "justify">Here, the best position of other members of the swarm has more impact on particle‚Äôs velocity that leads to pre mature convergence.</p></dd>
</dl>

<p align = "justify">
The acceleration coefficient was set to 2.00 in original paper [1]. But, acceleration coefficients with \(c1 = c2 = 1.49618\) provide good convergent behaviour [6,7]. 
</p>

<h3><i>Inertia weight</i></h3>

<p align = "justify">
The inertia weight model of PSO by Shi and Eberhart [8] employs a static inertia weight throughout the entirety of the search. \(\omega^t = 1.00\) (<code>'PSO'</code>) corresponding the original paper. \(\omega^t\) update templates are given below:
</p>

<table style = "width:100%">
    <tr>
        <td>\[\omega^{t+1} = \omega_{max} \]</td>
        <td><code>'PSO_0'</code> [1]</td>
        <td><p align = "right">(3)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = \omega_{max} - (\omega_{max} - \omega_{min}).\frac{t}{N_{iter}}\]</td>
        <td><code>'PSO_1'</code> [8,9]</td>
        <td><p align = "right">(4)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = \omega_{max} - (\omega_{max} - \omega_{min}).\left(\frac{t}{N_{iter}}\right)^\alpha, \alpha=\frac{1}{\pi^2}\]</td>
        <td><code>'PSO_2'</code> [9,10]</td>
        <td><p align = "right">(5)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = \left(\frac{2}{t}\right)^{0.30}\]</td>
        <td><code>'PSO_3'</code> [9,11]</td>
        <td><p align = "right">(6)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = \omega_{min} + \left(\omega_{max} - \omega_{min}\right).e^{\frac{-10.t}{N_{iter}}}\]</td>
        <td><code>'PSO_4'</code> [9,12]</td>
        <td><p align = "right">(7)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = \omega_{max} + \left(\omega_{min} - \omega_{max}\right).\log_{10}\left(1+\frac{10.t}{n_{iter}}\right)\]</td>
        <td><code>'PSO_5'</code> [9,13]</td>
        <td><p align = "right">(8)</p></td>
    </tr>
    <tr>
        <td>\[\omega^{t+1} = 0.50 + \frac{r(t)}{2}\]</td>
        <td><code>'PSO_6'</code> [9,14]</td>
        <td><p align = "right">(9)</p></td>
    </tr>
</table>

<p align = "justify">
\(n_{iter}\) is the maximum number of iterations. \(r(t)\) is a random numbers drawn from a uniform distribuition at time \(t\).
</p>

<h3><i>Algorithm</i></h3>

```python
1:  Input initial parameters (C_1,C_2)
2:  X = Initial solution
3:  for T in range(N_ITER):
4:      Calculate OF and FIT      
5:      History personal best solution
6:      History global best solution
7:      V(T+1) = update velocity equation (1) # including velocity clamping
8:      X(T+1) = update solution equation (2)
9:      Update inertia weight
```

<h3><i>References</i></h3>
<p align = "justify">
    [1]	J. Kennedy, R. Eberhart, Particle swarm optimization, in: Proceedings of ICNN‚Äô95 - International Conference on Neural Networks, IEEE, Perth, WA, Australia, 1995: pp. 1942‚Äì1948. https://doi.org/10.1109/ICNN.1995.488968.<br>
    [2] Eberhart, Yuhui Shi, Particle swarm optimization: developments, applications and resources, in: Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546), IEEE, Seoul, South Korea, 2001: pp. 81‚Äì86. https://doi.org/10.1109/CEC.2001.934374.<br>
    [3] M. Omran, A.P. Engelbrecht, A. Salman, Particle Swarm Optimization method for image clustering, Int. J. Patt. Recogn. Artif. Intell. 19 (2005) 297‚Äì321. https://doi.org/10.1142/S0218001405004083.<br>
    [4] Jain, M.; Saihjpal, V.; Singh,N.; Singh, S.B. An Overview of Variants and Advancements of PSO Algorithm. Appl. Sci. 2022, 12, 8392. https://doi.org/10.3390/app12178392.<br>
    [5] Houssein, E. H., Gad, A. G., Hussain, K., & Suganthan, P. N. (2021). Major Advances in Particle Swarm Optimization: Theory, Analysis, and Application. Swarm and Evolutionary Computation, 63, 100868. doi:10.1016/j.swevo.2021.100868.<br>
    [6] F. van den Bergh, A.P. Engelbrecht, A. (2006). A study of particle swarm optimization particle trajectories. Information Sciences, 176(8), 937‚Äì971. doi:10.1016/j.ins.2005.02.003¬†<br>
    [7] Eberhart, R. C., & Shi, Y. (n.d.). Comparing inertia weights and constriction factors in particle swarm optimization. Proceedings of the 2000 Congress on Evolutionary Computation. CEC00 (Cat. No.00TH8512). doi:10.1109/cec.2000.870279.¬†<br>
    [8] Shi, Y., & Eberhart, R. (n.d.). A modified particle swarm optimizer. 1998 IEEE International Conference on Evolutionary Computation Proceedings. IEEE World Congress on Computational Intelligence (Cat. No.98TH8360). doi:10.1109/icec.1998.699146.<br>
    [9] Harrison, K. R., Engelbrecht, A. P., & Ombuki-Berman, B. M. (2016). Inertia weight control strategies for particle swarm optimization. Swarm Intelligence, 10(4), 267‚Äì305. doi:10.1007/s11721-016-0128-z.<br>
    [10] Yang, C., Gao, W., Liu, N., & Song, C. (2015). Low-discrepancy sequence initialized particle swarm optimization algorithm with high-order nonlinear time-varying inertia weight. Applied Soft Computing, 29, 386‚Äì394. doi:10.1016/j.asoc.2015.01.004.<br>
    [11] Fan, S.-K. S., & Chiu, Y.-Y. (2007). A decreasing inertia weight particle swarm optimizer. Engineering Optimization, 39(2), 203‚Äì228. doi:10.1080/03052150601047362.¬† <br>
    [12] Guimin Chen, Xinbo Huang, Jianyuan Jia, & Zhengfeng Min. (2006). Natural Exponential Inertia Weight Strategy in Particle Swarm Optimization. 2006 6th World Congress on Intelligent Control and Automation. doi:10.1109/wcica.2006.1713055.<br>
    [13] Gao, Y., An, X., & Liu, J. (2008). A Particle Swarm Optimization Algorithm with Logarithm Decreasing Inertia Weight and Chaos Mutation. 2008 International Conference on Computational Intelligence and Security. doi:10.1109/cis.2008.183.<br> 
    [14] Eberhart, R. C., & Yuhui Shi. (n.d.). Tracking and optimizing dynamic systems with particle swarms. Proceedings of the 2001 Congress on Evolutionary Computation (IEEE Cat. No.01TH8546). doi:10.1109/cec.2001.934376. 
</p>

<h2>Framework</h2>

<h3><i>Algorithm functions</i></h3>

<h4>Input variables</h4>

<table style = "width:100%">
    <tr>
        <td>OF_FUNCTION</td>
        <td>External def user input this function in arguments</td>
        <td>Py function</td>
    </tr>
    <tr>
        <td>SETUP</td>
        <td>Algorithm setup</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'N_REP' = Number of repetitions</td>
        <td>Integer</td>
    </tr>    
    <tr>
        <td></td>
        <td>'N_ITER' = Number of iterations</td>
        <td>Integer</td>
    </tr> 
    <tr>
        <td></td>
        <td>'N_POP' = Number of population</td>
        <td>Integer</td>
    </tr>
    <tr>
        <td></td>
        <td>'D' = Problem dimension</td>
        <td>Integer</td>
    </tr>  
    <tr>
        <td></td>
        <td>'X_L' = Lower limit design variables</td>
        <td>Py list[D]</td>
    </tr> 
    <tr>
        <td></td>
        <td>'X_U' = Upper limit design variables</td>
        <td>Py list[D]</td>
    </tr>
    <tr>
        <td></td>
        <td>'NULL_DIC' = Empty variable for the user to use in the obj. function</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'PARAMETERS' = Algorithm parameters</td>
        <td>Py dictionary</td>
    </tr>    
    <tr>
        <td>PARAMETERS</td>
        <td>Algorithm parameters</td>
        <td>Py dictionary</td>
    </tr> 
    <tr>
        <td></td>
        <td>'MIN. VELOCITY (V_MIN)' = Lower boundary of the velocity (\(\symbf{v}_{min}\))</td>
        <td>Py list</td>
    </tr>
    <tr>
        <td></td>
        <td>'MAX. VELOCITY (V_MAX)' = Upper boundary of the velocity (\(\symbf{v}_{max}\))</td>
        <td>Py list</td>
    </tr>
        <td></td>
        <td>'COGNITIVE COEFFICIENT (C_1)' = Cognitive coefficient (\(c_{1}\))</td>
        <td>Float</td>
    </tr>
    </tr>
        <td></td>
        <td>'SOCIAL COEFFICIENT (C_2)' = Social coefficient (\(c_{2}\))</td>
        <td>Float</td>
    </tr>
    <tr>
        <td></td>
        <td>'MIN. INTERIA (W_MIN)' = Lower boundary of the inertia (\(\omega_{min}\))</td>
        <td>Float</td>
    </tr>
    <tr>
        <td></td>
        <td>'MAX. INERTIA (W_MAX)' = Upper boundary of the inertia (\(\omega_{max}\))</td>
        <td>Float</td>
    </tr>
    <tr>
        <td></td>
        <td>'INERTIA UPDATE' = \(\omega\) update see equation (3) <code>'PSO 0'</code> to equation (9) <code>'PSO 6'</code></td>
        <td>String</td>
    </tr>
</table>

<h4>Output variables</h4>

<table style = "width:100%">
    <tr>
        <td>RESULTS_REP</td>
        <td>All results of population movement by repetition</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'X_POSITION' = Design variables by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x D]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'OF' = Obj function value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'FIT' = Fitness value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'PARAMETERS' = Algorithm parameters</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'NEOF' = Number of objective function evaluations</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>
    <tr>
        <td></td>
        <td>'ID_PARTICLE' = ID particle</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td>BEST_REP</td>
        <td>Best population results by repetition</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'X_POSITION' = Design variables by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x D]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'OF' = Obj function value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'FIT' = Fitness value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'PARAMETERS' = Algorithm parameters</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'NEOF' = Number of objective function evaluations</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>
    <tr>
        <td></td>
        <td>'ID_PARTICLE' = ID particle</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr> 
    <tr>
        <td>AVERAGE_REP</td>
        <td>Average OF and FIT results by repetition</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'OF' = Obj function value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'FIT' = Fitness value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'NEOF' = Number of objective function evaluations</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>
    <tr>
        <td>WORST_REP</td>
        <td>Worst OF and FIT results by repetition</td>
        <td>Py dictionary</td>
    </tr>
    <tr>
        <td></td>
        <td>'X_POSITION' = Design variables by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x D]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'OF' = Obj function value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'FIT' = Fitness value by iteration</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'PARAMETERS' = Algorithm parameters</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>  
    <tr>
        <td></td>
        <td>'NEOF' = Number of objective function evaluations</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr>
    <tr>
        <td></td>
        <td>'ID_PARTICLE' = ID particle</td>
        <td>Py Numpy array[N_ITER + 1 x 1]</td>
    </tr> 
    <tr>
        <td>STATUS_PROCEDURE</td>
        <td>Process repetition ID - from lowest OF value to highest OF value</td>
        <td>Py list[N_REP]</td>
    </tr> 
</table>

<h3><i>Notebook</i></h3>

<p align = "justify">See Jupyter notebook example:</p>

```python
from META_TOOLBOX import FIREFLY_ALGORITHM_001 # or from META_TOOLBOX import *
from META_TOOLBOX import GAMMA_ASSEMBLY

# Input
X_L = [-2, -2, -2]
X_U = [2, 2, 2]
D = 3
V_MAX = [2, 2, 2]
V_MIN = [-2, -2, -2]

PARAMETERS = {
              'MIN VELOCITY (V_MIN)': V_MIN,
              'MAX VELOCITY (V_MAX)': V_MAX,
              'COGNITIVE COEFFICIENT (C_1)': 2.00,
              'SOCIAL COEFFICIENT (C_2)': 2.00,
              'MIN INTERIA (W_MIN)': None,
              'MAX INERTIA (W_MAX)': 1.00,
              'INERTIA UPDATE': 'PSO 0'
             }

SETUP = {
        'N_REP': 10,
        'N_POP': 5,
        'N_ITER': 100,
        'X_L': X_L,
        'X_U': X_U,
        'D': D,
        'NULL_DIC': None,
        'PARAMETERS': PARAMETERS
        }

# OF statement
def OF_FUNCTION(X, NULL_DIC):
    X_0 = X[0]
    X_1 = X[1]
    X_2 = X[2]
    OF = X_0 ** 2 + X_1 ** 2 + X_2 ** 2
    return OF

# Call algorithm
RESULTS_REP, BEST_REP, AVERAGE_REP, WORST_REP, STATUS_PROCEDURE = FIREFLY_ALGORITHM_001(OF_FUNCTION, SETUP)
```
```console
Output:
Progress: |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100.0% Complete
Process Time: 0.80 Seconds 
 Seconds per repetition: 0.08
META_FA001_REP_0_BEST_0_20230210 214404.xlsx
META_FA001_REP_1_BEST_1_20230210 214404.xlsx
META_FA001_REP_2_BEST_2_20230210 214404.xlsx
META_FA001_REP_3_BEST_3_20230210 214404.xlsx
META_FA001_REP_4_BEST_4_20230210 214404.xlsx
META_FA001_REP_5_BEST_5_20230210 214404.xlsx
META_FA001_REP_6_BEST_6_20230210 214404.xlsx
META_FA001_REP_7_BEST_7_20230210 214404.xlsx
META_FA001_REP_8_BEST_8_20230210 214404.xlsx
META_FA001_REP_9_BEST_9_20230210 214404.xlsx
META_FA001_RESUME_20230210 214404.xlsx
```
